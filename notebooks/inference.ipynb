{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from pytorch_lightning import Trainer\n",
    "from src.model import chained_seq2seq\n",
    "from src.data_modules_2 import STTDataModule2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_encoder = AutoTokenizer.from_pretrained(\"../model/opus-mt-nl-en\")\n",
    "ckpt_path = \"../model/checkpoints/chained_seq2seq_logs/version_1/checkpoints/epoch=4-step=9075.ckpt\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = STTDataModule2(num_workers = 12)\n",
    "dm.setup(\"fit\")\n",
    "dm.setup(\"test\")\n",
    "\n",
    "train_dataloader = dm.train_dataloader()\n",
    "val_dataloader = dm.val_dataloader()\n",
    "test_dataloader = dm.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = chained_seq2seq()\n",
    "model.eval()\n",
    "model.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1 if torch.cuda.is_available() else None,\n",
    "    default_root_dir=\"../model/checkpoints/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at ../model/checkpoints/chained_seq2seq_logs/version_1/checkpoints/epoch=4-step=9075.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at ../model/checkpoints/chained_seq2seq_logs/version_1/checkpoints/epoch=4-step=9075.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc00c17d43fc497289da810a056cfcd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test/cer            1.9862076044082642\n",
      "        test/loss             8.5058012008667\n",
      "        test/wer            1.9862076044082642\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test/loss': 8.5058012008667,\n",
       "  'test/wer': 1.9862076044082642,\n",
       "  'test/cer': 1.9862076044082642}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, datamodule=dm, ckpt_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../model/checkpoints/chained_seq2seq_logs/version_1/hparams.yaml\") as f:\n",
    "    hparams = yaml.safe_load(f)\n",
    "inferencer = chained_seq2seq.load_from_checkpoint(checkpoint_path=ckpt_path).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_src, samp_tgt = next(iter(test_dataloader))\n",
    "src_ids = tokenizer_encoder(samp_src, return_tensors=\"pt\", padding=True).input_ids.to(device)\n",
    "tgt_ids = tokenizer_encoder(samp_tgt, return_tensors=\"pt\",padding=True).input_ids.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(src_ids, tgt_ids)\n",
    "loss, logits = outputs[:2]\n",
    "generated = inferencer.generate(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de abbneazen zijn de oorspronkelijke inwoners van Australiëstraalië de de de de de',\n",
       " 'Mijn toetsenbord zit mijn mijn mijn mijn mijn mijn mijn mijn mijn mijn mijn mijn',\n",
       " 'Ze had de bank beschadigd met haar skateboard Ze Ze Ze Ze Ze',\n",
       " 'Deze top heeft niet in alle opzichten aan de verwachtingen voldaan De De De De De De De De De',\n",
       " 'waar je jeij je onderhoud doen waar waar waar waar waar waar waar waar waar waar waar waar',\n",
       " 'de commissaris,dankt voor uw zeer nauwkeurige antwoorden De De De De De De De De De De',\n",
       " 'Na het lezen van vele rec had ze eindelijk haar oog laten vallen op een laptop met een toetsenyybord',\n",
       " 'Ik maak daar mijn mijn tegen dat mijn probeert van te makengradstr Ik Ik Ik',\n",
       " 'Wat betekent deze in in?? De De De De Wat Wat Wat Wat Wat Wat Wat Wat Wat Wat Wat Wat Wat Wat',\n",
       " 'zijnvon zijn aan zijn zijn zijn zijn zijn zijn zijn zijn zijn zijn zijn zijn zijn zijn zijn',\n",
       " 'Pro we de te te verminderen of proberen wij energie energieverbruik te te dringen De De De De De',\n",
       " 'Maarm eringoliivier nu al meer dan twee jaar maar Maar Maar Maar Maar Maar Maar Maar Maar',\n",
       " 'Ike is dat onverdraagwikbaar Ik Ik Ik Ik Ik Ik Ik Ik Ik Ik Ik Ik',\n",
       " 'Het voeden van brood aan eenden is eigenlijk ongezond voor de beesten',\n",
       " 'Dit jaar het te veel. jullie jullie jullie jullie jullie jullie jullie jullie jullie jullie jullie jullie jullie jullie jullie',\n",
       " 'raketet je je stofzuigen tegels moet je dweilen raket raket raket raket raket raket']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de aboriginals zijn de oorspronkelijke bewoners van australië',\n",
       " 'mijn toetsenbord zit vol stof',\n",
       " 'ze had de bank beschadigd met haar skateboard',\n",
       " 'deze top heeft niet in alle opzichten aan de verwachtingen voldaan',\n",
       " 'waar laat jij je onderhoud doen',\n",
       " 'mijnheer de commissaris bedankt voor uw bijzonder nauwkeurige antwoorden',\n",
       " 'na het lezen van vele beoordelingen had ze eindelijk haar oog laten vallen op een laptop met een qwerty toetsenbord',\n",
       " 'ik maak er ernstig bezwaar tegen wanneer men een volk tracht te demoniseren',\n",
       " 'wat houdt dit vraagstuk in',\n",
       " 'de tampons zijn op',\n",
       " 'proberen wij kooldioxideemissies te beperken of proberen wij het energiegebruik terug te dringen',\n",
       " 'marijke kent olivier nu al meer dan twee jaar',\n",
       " 'mijn partij vindt dat onverkwikkelijk',\n",
       " 'het voeren van brood aan eenden is eigenlijk ongezond voor de beesten',\n",
       " 'juni dit jaar is veel te laat',\n",
       " 'parket moet je stofzuigen tegels moet je dweilen']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a3b7c7159b609b6d6ed4cb8640074f3b1e9bee62f57677af0169d92fbf130be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
