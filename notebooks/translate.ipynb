{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "sys.path.append(\"../\")\n",
    "import string\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from typing import Any\n",
    "from loguru import logger\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModelForSeq2SeqLM\n",
    "from transformers import MarianTokenizer, MarianMTModel\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse src_tgt training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../data/common_voice_nl/train.tsv\"\n",
    "df = pd.read_csv(filepath, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29031/29031 [00:00<00:00, 32567.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "      <th>stt_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>da4b6d09a23e8a83f83fec4e302a82c500d2821c4bb4d4...</td>\n",
       "      <td>common_voice_nl_30382934.mp3</td>\n",
       "      <td>een daadwerkelijke keuzevrijheid voor ouderen ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nederlands Nederlands</td>\n",
       "      <td>nl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>een daadwerkelijke keuzevrijheid voor ouderen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>da4b6d09a23e8a83f83fec4e302a82c500d2821c4bb4d4...</td>\n",
       "      <td>common_voice_nl_30382935.mp3</td>\n",
       "      <td>elke kandidaatlidstaat moet op zijn eigen meri...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nederlands Nederlands</td>\n",
       "      <td>nl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>elke kandidaat dit staat moet op zijn eigen wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>da4b6d09a23e8a83f83fec4e302a82c500d2821c4bb4d4...</td>\n",
       "      <td>common_voice_nl_30382936.mp3</td>\n",
       "      <td>het verslag legt sterke nadruk op het nauwe ve...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nederlands Nederlands</td>\n",
       "      <td>nl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>het verslag legt sterke nadruk op het nauwe ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>da4b6d09a23e8a83f83fec4e302a82c500d2821c4bb4d4...</td>\n",
       "      <td>common_voice_nl_30382937.mp3</td>\n",
       "      <td>wij openen nu het algemeen debat</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nederlands Nederlands</td>\n",
       "      <td>nl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>we openen nu het algemeen debat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>da4b6d09a23e8a83f83fec4e302a82c500d2821c4bb4d4...</td>\n",
       "      <td>common_voice_nl_30382938.mp3</td>\n",
       "      <td>die fase is gebaseerd op de testcyclus van per...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nederlands Nederlands</td>\n",
       "      <td>nl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>die fase is gebaseerd op de test van personena...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  da4b6d09a23e8a83f83fec4e302a82c500d2821c4bb4d4...   \n",
       "1  da4b6d09a23e8a83f83fec4e302a82c500d2821c4bb4d4...   \n",
       "2  da4b6d09a23e8a83f83fec4e302a82c500d2821c4bb4d4...   \n",
       "3  da4b6d09a23e8a83f83fec4e302a82c500d2821c4bb4d4...   \n",
       "4  da4b6d09a23e8a83f83fec4e302a82c500d2821c4bb4d4...   \n",
       "\n",
       "                           path  \\\n",
       "0  common_voice_nl_30382934.mp3   \n",
       "1  common_voice_nl_30382935.mp3   \n",
       "2  common_voice_nl_30382936.mp3   \n",
       "3  common_voice_nl_30382937.mp3   \n",
       "4  common_voice_nl_30382938.mp3   \n",
       "\n",
       "                                            sentence  up_votes  down_votes  \\\n",
       "0  een daadwerkelijke keuzevrijheid voor ouderen ...         2           0   \n",
       "1  elke kandidaatlidstaat moet op zijn eigen meri...         2           0   \n",
       "2  het verslag legt sterke nadruk op het nauwe ve...         2           0   \n",
       "3                   wij openen nu het algemeen debat         4           0   \n",
       "4  die fase is gebaseerd op de testcyclus van per...         4           0   \n",
       "\n",
       "   age gender                accents locale  segment  \\\n",
       "0  NaN    NaN  Nederlands Nederlands     nl      NaN   \n",
       "1  NaN    NaN  Nederlands Nederlands     nl      NaN   \n",
       "2  NaN    NaN  Nederlands Nederlands     nl      NaN   \n",
       "3  NaN    NaN  Nederlands Nederlands     nl      NaN   \n",
       "4  NaN    NaN  Nederlands Nederlands     nl      NaN   \n",
       "\n",
       "                                             stt_out  \n",
       "0  een daadwerkelijke keuzevrijheid voor ouderen ...  \n",
       "1  elke kandidaat dit staat moet op zijn eigen wo...  \n",
       "2  het verslag legt sterke nadruk op het nauwe ve...  \n",
       "3                    we openen nu het algemeen debat  \n",
       "4  die fase is gebaseerd op de test van personena...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stt = []\n",
    "for fname in tqdm(df.path.values):\n",
    "    with open(f\"../data/common_voice_nl/cv_nl_stt/{fname}.json\", \"r+\") as f:\n",
    "        stt_out = json.load(f)\n",
    "        all_stt.append(stt_out['results']['channels'][0]['alternatives'][0]['transcript'])\n",
    "df['stt_out'] = pd.Series(all_stt)\n",
    "df['sentence'] = df.sentence.str.lower()\n",
    "df['sentence'] = df.sentence.apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test NMT based Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 5\n",
    "noisy_seq = df.stt_out.iloc[:idx]\n",
    "clean_seq = df.sentence.iloc[:idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Marianseq_infer(src_seq):\n",
    "#     logger.info(f\"Initial (Noisy) Sequence = {src_seq}\")\n",
    "#     tokenizer_nl_en = MarianTokenizer.from_pretrained(\"../model/opus-mt-nl-en\")\n",
    "#     nl_en = MarianMTModel.from_pretrained(\"../model/opus-mt-nl-en\")\n",
    "    \n",
    "#     tokenizer_en_nl = MarianTokenizer.from_pretrained(\"../model/opus-mt-en-nl\")\n",
    "#     en_nl = MarianMTModel.from_pretrained(\"../model/opus-mt-en-nl\")\n",
    "\n",
    "#     encoder_batch = tokenizer_nl_en([src_seq], return_tensors=\"pt\")\n",
    "#     outputs_interim = nl_en.generate(**encoder_batch)\n",
    "#     interim_seq = tokenizer_nl_en.batch_decode(outputs_interim, skip_special_tokens=True)[0]\n",
    "    \n",
    "#     logger.info(f\"Interim Sequence  = {interim_seq}\")\n",
    "    \n",
    "#     decoder_batch = tokenizer_en_nl([interim_seq], return_tensors=\"pt\")\n",
    "#     outputs_final = en_nl.generate(**decoder_batch)\n",
    "#     tgt_seq = tokenizer_en_nl.batch_decode(outputs_final, skip_special_tokens=True)[0]\n",
    "    \n",
    "#     logger.info(f\"Final Sequence  = {tgt_seq}\")\n",
    "#     return tgt_seq\n",
    "# Marianseq_infer(noisy_seq)\n",
    "# logger.info(f\"Ground Truth Sequence = {clean_seq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_infer(src_batch):\n",
    "    logger.info(f\"Initial (Noisy) Sequence = {src_batch}\")\n",
    "    tokenizer_nl_en = AutoTokenizer.from_pretrained(\"../model/opus-mt-nl-en\")\n",
    "    nl_en = AutoModelForSeq2SeqLM.from_pretrained(\"../model/opus-mt-nl-en\").to(device)\n",
    "    \n",
    "    tokenizer_en_nl = AutoTokenizer.from_pretrained(\"../model/opus-mt-en-nl\")\n",
    "    en_nl = AutoModelForSeq2SeqLM.from_pretrained(\"../model/opus-mt-en-nl\").to(device)\n",
    "\n",
    "    encoder_input_ids = tokenizer_nl_en(src_batch, return_tensors=\"pt\", padding=True).input_ids.to(device)\n",
    "    outputs_interim = nl_en.generate(encoder_input_ids, num_beams=5, max_new_tokens=512)\n",
    "    interim_batch = tokenizer_nl_en.batch_decode(outputs_interim, skip_special_tokens=True)\n",
    "    \n",
    "    logger.info(f\"Interim Sequence  = {interim_batch}\")\n",
    "    \n",
    "    decoder_input_ids = tokenizer_en_nl(interim_batch, return_tensors=\"pt\", padding=True).input_ids.to(device)\n",
    "    outputs_final = en_nl.generate(decoder_input_ids, num_beams=5, max_new_tokens=512)\n",
    "    tgt_batch = tokenizer_en_nl.batch_decode(outputs_final, skip_special_tokens=True)\n",
    "\n",
    "    return tgt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-18 03:33:16.787 | INFO     | __main__:seq2seq_infer:2 - Initial (Noisy) Sequence = ['een daadwerkelijke keuzevrijheid voor ouderen daar zouden we werk van moeten maken', 'elke kandidaat dit staat moet op zijn eigen worden beoordeeld', 'het verslag legt sterke nadruk op het nauwe verband tussen de twee', 'we openen nu het algemeen debat', \"die fase is gebaseerd op de test van personenauto's\"]\n",
      "2022-09-18 03:33:21.430 | INFO     | __main__:seq2seq_infer:13 - Interim Sequence  = ['a genuine freedom of choice for older people.', 'each candidate this state must be judged on its own', 'the report places strong emphasis on the close link between the two', 'We are now opening the general debate', 'that phase is based on the test of passenger cars']\n",
      "2022-09-18 03:33:21.557 | INFO     | __main__:<module>:2 - Final Sequence  = ['een echte keuzevrijheid voor ouderen.', 'elke kandidaat deze staat moet worden beoordeeld op zijn eigen', 'In het verslag wordt sterk de nadruk gelegd op het nauwe verband tussen de twee', 'Wij openen nu het algemene debat', \"die fase is gebaseerd op de test van personenauto's\"]\n",
      "2022-09-18 03:33:21.558 | INFO     | __main__:<module>:3 - Ground Truth Sequence = ['een daadwerkelijke keuzevrijheid voor ouderen daar zouden we werk van moeten maken', 'elke kandidaatlidstaat moet op zijn eigen merites worden beoordeeld', 'het verslag legt sterke nadruk op het nauwe verband tussen de twee', 'wij openen nu het algemeen debat', 'die fase is gebaseerd op de testcyclus van personenautos']\n"
     ]
    }
   ],
   "source": [
    "tgt_batch = seq2seq_infer(noisy_seq.values.tolist())\n",
    "logger.info(f\"Final Sequence  = {tgt_batch}\")\n",
    "logger.info(f\"Ground Truth Sequence = {clean_seq.values.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Custom Dataset and a Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df) -> None:\n",
    "        super().__init__()\n",
    "        self.src = df.stt_out.values.tolist()\n",
    "        self.tgt = df.sentence.values.tolist()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tgt)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        source_text = self.src[index]\n",
    "        target_text = self.tgt[index]\n",
    "        sample = {\"src\": source_text, \"tgt\": target_text}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):    \n",
    "     source = [x['src'].strip() for x in batch]\n",
    "     target = [x['tgt'].strip() for x in batch]\n",
    "     return source, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up Pytorch Lightning based Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.rand(5, 17, 67028)\n",
    "# b = torch.rand(5, 17)\n",
    "# a[-1, :].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "\n",
    "- Forward pass of en-nl implemented successfully. Can I also use forward pass of the encoder(nl-en)?\n",
    "- Dataloader: Pass tokenized sequences in batch instead or text\n",
    "- Implement WER metric tracking\n",
    "- Implement callbacks\n",
    "- Implement validation step and a custom generate function\n",
    "- Move all code to src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class chained_seq2seq(LightningModule):\n",
    "    def __init__(self, *args: Any, **kwargs: Any) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.tokenizer_encoder = AutoTokenizer.from_pretrained(\"../model/opus-mt-nl-en\")\n",
    "        self.encoder = AutoModelForSeq2SeqLM.from_pretrained(\"../model/opus-mt-nl-en\").to(device)\n",
    "        \n",
    "        self.tokenizer_decoder = AutoTokenizer.from_pretrained(\"../model/opus-mt-en-nl\")\n",
    "        self.decoder = AutoModelForSeq2SeqLM.from_pretrained(\"../model/opus-mt-en-nl\").to(device)\n",
    "        # output is logits. CE loss applies log_softmax to logits and then computes nll loss\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=self.tokenizer_decoder.pad_token_id)\n",
    "    \n",
    "    def forward(self, inputs, tgt_ids):\n",
    "        encoder_input_ids = self.tokenizer_encoder(inputs, return_tensors=\"pt\", padding=True).input_ids.to(device)\n",
    "        # logger.info(f\"source batch size = {encoder_input_ids.size()}\")\n",
    "        outputs_interim = self.encoder.generate(encoder_input_ids, num_beams=5, max_new_tokens=512) \n",
    "        interim_batch = self.tokenizer_encoder.batch_decode(outputs_interim, skip_special_tokens=True)\n",
    "\n",
    "        decoder_input_ids = self.tokenizer_decoder(interim_batch, return_tensors=\"pt\", padding=True).input_ids.to(device)\n",
    "        decoder_attention_masks = self.tokenizer_decoder(interim_batch, return_tensors=\"pt\", padding=True).attention_mask.to(device)\n",
    "        outputs_final = self.decoder(input_ids=decoder_input_ids, attention_mask = decoder_attention_masks, labels=tgt_ids)\n",
    "\n",
    "        return outputs_final\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        src_batch, tgt_batch = batch\n",
    "        tgt_batch = self.tokenizer_encoder(tgt_batch, return_tensors=\"pt\",padding=True).input_ids.to(device)\n",
    "\n",
    "        outputs = self.forward(src_batch, tgt_batch)\n",
    "        loss, logits = outputs[:2]\n",
    "\n",
    "        # logger.info(f\"target batch size = {tgt_batch.size()}\")\n",
    "        # logger.info(f\"model output shape = {logits.size()}\")\n",
    "        # logger.info(f\"returned loss = {loss}, calculated loss={self.criterion(logits[-1, :], tgt_batch[-1, :])}\")\n",
    "        self.log_dict({\n",
    "            'train_loss': loss\n",
    "        })\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "\n",
    "        return {'loss': loss, 'log': tensorboard_logs}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        ds = CustomDataset(df)\n",
    "        dl = DataLoader(\n",
    "            ds,\n",
    "            shuffle=True,  # False, if overfit_pct\n",
    "            batch_size=batch_size,\n",
    "            num_workers=12,\n",
    "            collate_fn=collate_batch)\n",
    "        print(\n",
    "            f\"dataset:'{'train'}', size:{len(ds)}, batch:{batch_size}, nb_batches:{len(dl)}\"\n",
    "        )\n",
    "        return dl\n",
    "\n",
    "    def generate(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "model = chained_seq2seq()\n",
    "trainer = pl.Trainer(max_epochs=5, accelerator=\"auto\", callbacks=[TQDMProgressBar(refresh_rate=10)], devices=1 if torch.cuda.is_available() else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | encoder   | MarianMTModel    | 79.0 M\n",
      "1 | decoder   | MarianMTModel    | 79.0 M\n",
      "2 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "156 M     Trainable params\n",
      "1.0 M     Non-trainable params\n",
      "157 M     Total params\n",
      "631.849   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:'train', size:29031, batch:16, nb_batches:1815\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7acf3fa26d7a478492f074e5aa9c9f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anand/Development/tinkering/stt_postprocess/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:653: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = chained_seq2seq().eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../model/opus-mt-en-nl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad>'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['een echte keuzevrijheid voor ouderen.',\n",
       " 'elke kandidaat deze staat moet worden beoordeeld op zijn eigen',\n",
       " 'In het verslag wordt sterk de nadruk gelegd op het nauwe verband tussen de twee',\n",
       " 'Wij openen nu het algemene debat',\n",
       " \"die fase is gebaseerd op de test van personenauto's\"]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(model(noisy_seq.values.tolist()), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a3b7c7159b609b6d6ed4cb8640074f3b1e9bee62f57677af0169d92fbf130be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
