{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from jiwer import wer\n",
    "\n",
    "from src.model_2 import chained_seq2seq\n",
    "from src.utils import STTDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = STTDataModule(device=device)\n",
    "dm.setup(\"fit\")\n",
    "dm.setup(\"test\")\n",
    "\n",
    "train_dataloader = dm.train_dataloader()\n",
    "val_dataloader = dm.val_dataloader()\n",
    "test_dataloader = dm.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer_encoder = AutoTokenizer.from_pretrained(\"../model/opus-mt-nl-en\")\n",
    "tokenizer_decoder = AutoTokenizer.from_pretrained(\"../model/opus-mt-en-nl\")\n",
    "model = chained_seq2seq()\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_src, samp_tgt, samp_en = next(iter(test_dataloader))\n",
    "src_ids = tokenizer_encoder(samp_src, return_tensors=\"pt\", padding=True).input_ids.to(device)\n",
    "tgt_ids = tokenizer_encoder(samp_tgt, return_tensors=\"pt\",padding=True).input_ids.to(device)\n",
    "\n",
    "interim_attn = tokenizer_encoder(samp_src, return_tensors=\"pt\", padding=True).attention_mask.to(device)\n",
    "interim_ids = tokenizer_decoder(samp_en, return_tensors=\"pt\", padding=True).input_ids.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 17:26:30.910 | INFO     | src.model_2:forward:27 - source batch size = torch.Size([16, 23])\n",
      "2022-10-30 17:26:30.911 | INFO     | src.model_2:forward:28 - target batch size = torch.Size([16, 26])\n",
      "2022-10-30 17:26:30.911 | INFO     | src.model_2:forward:29 - interim batch size = torch.Size([16, 21])\n",
      "2022-10-30 17:26:30.911 | INFO     | src.model_2:forward:30 - interim mask size = torch.Size([16, 23])\n",
      "2022-10-30 17:26:30.938 | INFO     | src.model_2:forward:36 - middle_batch = ['the ab are▁inhabitants are the▁original▁inhabitants of astralia', 'my▁keyboard is are', '▁She had▁damaged the bank with her skateboard', '▁This▁summit▁has not met▁expectations in▁every▁respects', '▁where▁yougonna▁get▁your▁maintenance▁done', '▁Commissioner▁you for▁your▁very▁precise▁answers', '▁After▁reading▁many▁reviews had▁finally▁dropped her▁eye on a▁laptop with a▁keyboard▁key▁keyboard', 'I▁make▁urge to the to▁makeize the of', '▁What▁does▁this▁question▁mean▁what▁what▁what▁what▁what▁what▁what', 'therunons on', 'We we▁trying to▁reduce▁emissions▁emissions▁emissions or are we▁trying to▁reduce▁energy', '▁Butle▁ol been forivier for more▁than▁two▁years', 'I opinion▁finds that is unexate', '▁Feeding▁bread to▁ducks is▁actually unhealthy for the▁animalsasts', '▁you▁year the from late', '▁rocketlor▁floor▁need to▁tiles▁you▁need to mop']\n"
     ]
    }
   ],
   "source": [
    "out_interim, out_final = model(src_ids, interim_ids, interim_attn, tgt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.7072, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(6.3065, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss_interim, logits_interim = out_interim[:2]\n",
    "loss_final, logits_final = out_final[:2]\n",
    "print(loss_interim, loss_final)\n",
    "generated = model.generate(logits_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3776223776223777"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wer(samp_tgt, generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['De abbbtainzen zijn de oorspronkelijke bewoners van Astraalië de de de de de de',\n",
       " 'Mijn toetsenbord is mijn mijn mijn mijn mijn mijn mijn mijn mijn mijn mijn mijn mijn mijn',\n",
       " 'Ze had de bank beschadigd met haar skateboard Ze Ze Ze Ze Ze',\n",
       " 'Deze top heeft niet in alle opzichten aan de verwachtingen voldaan De De De De De De De De De De',\n",
       " 'waar je jeij je onderhoud doen waar waar waar waar waar waar waar waar waar waar waar waar waar',\n",
       " 'de commissaris,dankt voor uw zeer nauwkeurige antwoorden De De De De De De De De De De Mijnheer',\n",
       " 'Na het lezen van veel rec had eindelijk eindelijk haar oog laten vallen op een laptop met een toetsenyy toetsenbord',\n",
       " 'Ik doe de de de tegen dat de de van te makengradstr dat De De De De',\n",
       " 'Wat betekent deze in in wat wat wat wat wat wat wat Wat Wat Wat Wat Wat Wat Wat Wat Wat Wat Wat Wat Wat Wat',\n",
       " 'derunroepons op de de de de de de de de de de de de de de de',\n",
       " 'Wij wij de te te verminderen of proberen wij energie energieverbruik terug te dringen Wij Wij Wij Wij Wij',\n",
       " 'De meerr meer¡ meer al meer meer dan twee jaar     ',\n",
       " 'Ik mening vindt dat nietmoeiwikd Ik Ik Ik Ik Ik Ik Ik Ik Ik Ik Ik',\n",
       " 'Het voeren van brood aan eenden is eigenlijk ongezond voor de dierenesten',\n",
       " 'je jaar de het later laat je je je je je je je je je je je je je je',\n",
       " 'raketetvloer u tegelsfigen jeweilen raket raket raket raket raket raket raket raket']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de aboriginals zijn de oorspronkelijke bewoners van australië',\n",
       " 'mijn toetsenbord zit vol stof',\n",
       " 'ze had de bank beschadigd met haar skateboard',\n",
       " 'deze top heeft niet in alle opzichten aan de verwachtingen voldaan',\n",
       " 'waar laat jij je onderhoud doen',\n",
       " 'mijnheer de commissaris bedankt voor uw bijzonder nauwkeurige antwoorden',\n",
       " 'na het lezen van vele beoordelingen had ze eindelijk haar oog laten vallen op een laptop met een qwerty toetsenbord',\n",
       " 'ik maak er ernstig bezwaar tegen wanneer men een volk tracht te demoniseren',\n",
       " 'wat houdt dit vraagstuk in',\n",
       " 'de tampons zijn op',\n",
       " 'proberen wij kooldioxideemissies te beperken of proberen wij het energiegebruik terug te dringen',\n",
       " 'marijke kent olivier nu al meer dan twee jaar',\n",
       " 'mijn partij vindt dat onverkwikkelijk',\n",
       " 'het voeren van brood aan eenden is eigenlijk ongezond voor de beesten',\n",
       " 'juni dit jaar is veel te laat',\n",
       " 'parket moet je stofzuigen tegels moet je dweilen']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a3b7c7159b609b6d6ed4cb8640074f3b1e9bee62f57677af0169d92fbf130be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
